{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "176b6a10",
   "metadata": {},
   "source": [
    "## Intent Classification Modeling\n",
    "\n",
    "The plan is to:\n",
    "\n",
    "* train, tune, and evaluate several different types of models\n",
    "  * k nearest neighbors\n",
    "  * logistic regression\n",
    "  * multinomial naive bayes\n",
    "  * support vector machine\n",
    "* choose a model based on the above experimentation and the below requirements\n",
    "\n",
    "Requirements:\n",
    "\n",
    "* simple models, no deep learning\n",
    "* accuracy >= 95%\n",
    "* reasonable training time\n",
    "* fast prediction time\n",
    "* low resource usage for inference\n",
    "\n",
    "We will use accuracy as our main optimizing metric. Our dataset is well-balanced,\n",
    "and there is no particular emphasis on precision or recall for our intent\n",
    "classification task. False positives and false negatives will both result in\n",
    "a misclassification, so they have a similar cost. We will look at accuracy for\n",
    "each class and the model overall to assess performance. We explore simpler\n",
    "modeling approaches, with the goal of excellent performance with some\n",
    "infrequent misclassifications allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aace44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from utils import (\n",
    "    init_nb, Timer, TFIDF_DATA_PATH, INTENT_LABELS_PATH, RANDOM_SEED, MODEL_DIR, DATA_DIR\n",
    ")\n",
    "\n",
    "init_nb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ccade",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "intent_labels = pd.read_json(INTENT_LABELS_PATH)\n",
    "str_labels = intent_labels.label_str.tolist()\n",
    "int_labels = intent_labels.label_int.tolist()\n",
    "\n",
    "# newest version\n",
    "timestamp = '1746644761'\n",
    "latest_tfidf_data = TFIDF_DATA_PATH.parent / f'data_tfidf_{timestamp}.jsonl'\n",
    "\n",
    "df = pd.read_json(latest_tfidf_data, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6835e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split into train, test, validation\n",
    "# use original dataset proportions: train=.66, test=.2, val=.133\n",
    "# just split dataframe, ignore features vs. target for now\n",
    "\n",
    "# split .66 train / .33 test & val\n",
    "df_train, df_test_val, _, _ = train_test_split(df, df, test_size=1/3, random_state=RANDOM_SEED) # test_size=test + val (.33)\n",
    "\n",
    "# split .133 val / .2 test\n",
    "df_val, df_test, _, _ = train_test_split(df_test_val, df_test_val, test_size=3/5, random_state=RANDOM_SEED) # test_size=test (.2 = 3/5 of 1/3)\n",
    "\n",
    "print(f'{len(df_train)=}')\n",
    "print(f'{len(df_test)=}')\n",
    "print(f'{len(df_val)=}')\n",
    "\n",
    "df_train.to_json(DATA_DIR / 'df_train.jsonl', orient='records', lines=True)\n",
    "df_test.to_json(DATA_DIR / 'df_test.jsonl', orient='records', lines=True)\n",
    "df_val.to_json(DATA_DIR / 'df_val.jsonl', orient='records', lines=True)\n",
    "\n",
    "# extract target\n",
    "y_train = df_train.intent.to_numpy()\n",
    "y_test = df_test.intent.to_numpy()\n",
    "y_val = df_val.intent.to_numpy()\n",
    "\n",
    "# extract features and create matrix required for classifiers\n",
    "X_train = np.vstack(df_train.tfidf_vector.to_numpy())\n",
    "X_test = np.vstack(df_test.tfidf_vector.to_numpy())\n",
    "X_val = np.vstack(df_val.tfidf_vector.to_numpy())\n",
    "\n",
    "print(f'{X_train.shape=}')\n",
    "print(f'{X_test.shape=}')\n",
    "print(f'{X_val.shape=}')\n",
    "print(f'{y_train.shape=}')\n",
    "print(f'{y_test.shape=}')\n",
    "print(f'{y_val.shape=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603c515d",
   "metadata": {},
   "source": [
    "```text\n",
    "len(df_train)=3005\n",
    "len(df_test)=902\n",
    "len(df_val)=601\n",
    "X_train.shape=(3005, 10688)\n",
    "X_test.shape=(902, 10688)\n",
    "X_val.shape=(601, 10688)\n",
    "y_train.shape=(3005,)\n",
    "y_test.shape=(902,)\n",
    "y_val.shape=(601,)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bbffec",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# k nearest neighbors\n",
    "with Timer('k nearest neighbors (untuned) training time'):\n",
    "    knn_default = KNeighborsClassifier(\n",
    "        n_neighbors=5,\n",
    "        weights='uniform', # all points in each neighborhood are weighted equally.\n",
    "        # weights='distance', # weigh points by the inverse of their distance, closer neighbors of a query point will have a greater influence than neighbors which are further away\n",
    "        algorithm='auto', # nearest neighbors algorithm ('brute', 'kd_tree', 'ball_tree')\n",
    "        leaf_size=30, # leaf size for kd_tree and ball_tree algorithms\n",
    "        p=2, # power parameter for Minkowski metric\n",
    "        metric='minkowski', # uses standard Euclidean distance when p=2 (can also be 'precomputed' or a Callable)\n",
    "        metric_params=None, # additional params for the metric function\n",
    "        n_jobs=-1, # use all processors for neighbor seach (no effect on fit)\n",
    "    )\n",
    "    knn_default.fit(X_train, y_train)\n",
    "with Timer('k nearest neighbors (untuned) test set eval time'):\n",
    "    y_pred_knn_default = knn_default.predict(X_test)\n",
    "\n",
    "print(classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred_knn_default,\n",
    "    labels=list(int_labels),\n",
    "    target_names=list(str_labels),\n",
    "    sample_weight=None,\n",
    "    digits=4,\n",
    "    output_dict=False,\n",
    "))\n",
    "\n",
    "pprint(knn_default.get_params())\n",
    "\n",
    "knn_params = {\n",
    "    'metric': ('minkowski', 'cosine'),\n",
    "    'n_neighbors': list(range(1, 31)),\n",
    "    'p': (1, 2),\n",
    "    'weights': ('distance', 'uniform'),\n",
    "}\n",
    "\n",
    "with Timer('k nearest neighbors hyperparameter tuning'):\n",
    "    knn_grid_search = GridSearchCV(\n",
    "        estimator=knn_default,\n",
    "        param_grid=knn_params,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1, # use all cpus\n",
    "        refit=True,\n",
    "        cv=5,\n",
    "        verbose=3,\n",
    "        error_score=np.nan,\n",
    "        return_train_score=False,\n",
    "    )\n",
    "    knn_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# parameter setting that gave the best results on the hold out data\n",
    "pprint(knn_grid_search.best_params_ )\n",
    "# mean cross-validated score of the best_estimator\n",
    "print('best score: ', knn_grid_search.best_score_)\n",
    "\n",
    "knn = knn_grid_search.best_estimator_\n",
    "\n",
    "with Timer('k nearest neighbors (tuned) test set eval time'):\n",
    "    y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "print(classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred_knn,\n",
    "    labels=list(int_labels),\n",
    "    target_names=list(str_labels),\n",
    "    sample_weight=None,\n",
    "    digits=4,\n",
    "    output_dict=False,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6986d153",
   "metadata": {},
   "source": [
    "```text\n",
    "k nearest neighbors (untuned) training time: 0.007960666989674792 seconds\n",
    "k nearest neighbors (untuned) test set eval time: 0.23888179200002924 seconds\n",
    "                      precision    recall  f1-score   support\n",
    "\n",
    "       are_you_a_bot     0.9444    0.9444    0.9444        18\n",
    "          calculator     1.0000    0.7879    0.8814        33\n",
    "                date     0.6364    0.9655    0.7671        29\n",
    "          definition     0.9032    0.8750    0.8889        32\n",
    "          find_phone     0.8800    1.0000    0.9362        22\n",
    "           flip_coin     1.0000    0.9355    0.9667        31\n",
    "food_beverage_recipe     0.7143    0.7143    0.7143        35\n",
    "             goodbye     0.9062    0.8788    0.8923        33\n",
    "            greeting     0.8710    0.8710    0.8710        31\n",
    "               maybe     0.7143    0.8333    0.7692        24\n",
    "     meaning_of_life     0.8250    0.8919    0.8571        37\n",
    "                  no     0.9286    0.7429    0.8254        35\n",
    "            reminder     0.8800    0.8462    0.8627        26\n",
    "     reminder_update     0.9429    0.9429    0.9429        35\n",
    "       shopping_list     0.7500    1.0000    0.8571        30\n",
    "shopping_list_update     0.9565    0.7586    0.8462        29\n",
    "            spelling     0.9630    0.8966    0.9286        29\n",
    "           tell_joke     0.9259    0.9259    0.9259        27\n",
    "                text     1.0000    0.9630    0.9811        27\n",
    "                time     0.8824    1.0000    0.9375        30\n",
    "               timer     0.8710    0.9000    0.8852        30\n",
    "           todo_list     0.6452    0.8000    0.7143        25\n",
    "    todo_list_update     0.8800    0.6875    0.7719        32\n",
    "             traffic     1.0000    0.8500    0.9189        40\n",
    "           translate     0.8276    0.9600    0.8889        25\n",
    "             weather     0.8333    0.7692    0.8000        26\n",
    "   what_is_your_name     0.7714    0.9643    0.8571        28\n",
    "        who_made_you     0.9697    0.8649    0.9143        37\n",
    "     word_of_the_day     0.9032    0.8485    0.8750        33\n",
    "                 yes     0.8800    0.6667    0.7586        33\n",
    "\n",
    "            accuracy                         0.8647       902\n",
    "           macro avg     0.8735    0.8695    0.8660       902\n",
    "        weighted avg     0.8774    0.8647    0.8655       902\n",
    "\n",
    "{'algorithm': 'auto',\n",
    " 'leaf_size': 30,\n",
    " 'metric': 'minkowski',\n",
    " 'metric_params': None,\n",
    " 'n_jobs': -1,\n",
    " 'n_neighbors': 5,\n",
    " 'p': 2,\n",
    " 'weights': 'uniform'}\n",
    "\n",
    "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
    "[CV 2/5] END metric=minkowski, n_neighbors=1, p=2, weights=distance;, score=0.852 total time=   0.6s\n",
    "[CV 1/5] END metric=minkowski, n_neighbors=1, p=2, weights=distance;, score=0.834 total time=   0.8s\n",
    "[truncated]\n",
    "[CV 4/5] END metric=cosine, n_neighbors=30, p=2, weights=uniform;, score=0.790 total time=   1.1s\n",
    "[CV 4/5] END metric=cosine, n_neighbors=29, p=1, weights=uniform;, score=0.790 total time=   0.2s\n",
    "\n",
    "k nearest neighbors hyperparameter tuning: 517.9623270409938 seconds\n",
    "{'metric': 'cosine', 'n_neighbors': 9, 'p': 1, 'weights': 'distance'}\n",
    "best score:  0.8532445923460898\n",
    "\n",
    "k nearest neighbors (tuned) test set eval time: 0.8965172089810949 seconds\n",
    "                      precision    recall  f1-score   support\n",
    "\n",
    "       are_you_a_bot     0.9000    1.0000    0.9474        18\n",
    "          calculator     1.0000    0.8182    0.9000        33\n",
    "                date     0.7568    0.9655    0.8485        29\n",
    "          definition     0.9630    0.8125    0.8814        32\n",
    "          find_phone     0.9167    1.0000    0.9565        22\n",
    "           flip_coin     1.0000    0.9355    0.9667        31\n",
    "food_beverage_recipe     0.7647    0.7429    0.7536        35\n",
    "             goodbye     0.9310    0.8182    0.8710        33\n",
    "            greeting     0.8333    0.8065    0.8197        31\n",
    "               maybe     0.8077    0.8750    0.8400        24\n",
    "     meaning_of_life     0.8974    0.9459    0.9211        37\n",
    "                  no     0.9655    0.8000    0.8750        35\n",
    "            reminder     0.9167    0.8462    0.8800        26\n",
    "     reminder_update     0.9118    0.8857    0.8986        35\n",
    "       shopping_list     0.7568    0.9333    0.8358        30\n",
    "shopping_list_update     0.9583    0.7931    0.8679        29\n",
    "            spelling     0.8966    0.8966    0.8966        29\n",
    "           tell_joke     0.9615    0.9259    0.9434        27\n",
    "                text     0.9600    0.8889    0.9231        27\n",
    "                time     0.8788    0.9667    0.9206        30\n",
    "               timer     0.8182    0.9000    0.8571        30\n",
    "           todo_list     0.6562    0.8400    0.7368        25\n",
    "    todo_list_update     0.9615    0.7812    0.8621        32\n",
    "             traffic     0.9730    0.9000    0.9351        40\n",
    "           translate     0.7742    0.9600    0.8571        25\n",
    "             weather     0.8462    0.8462    0.8462        26\n",
    "   what_is_your_name     0.7500    0.9643    0.8438        28\n",
    "        who_made_you     0.8947    0.9189    0.9067        37\n",
    "     word_of_the_day     0.8857    0.9394    0.9118        33\n",
    "                 yes     0.9200    0.6970    0.7931        33\n",
    "\n",
    "            accuracy                         0.8758       902\n",
    "           macro avg     0.8819    0.8801    0.8765       902\n",
    "        weighted avg     0.8858    0.8758    0.8764       902\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18d1e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "\n",
    "with Timer('logistic regression (untuned) training time'):\n",
    "    lr_default = LogisticRegression(\n",
    "        penalty = 'l2', # L2 regularization\n",
    "        dual = False, # dual (constrained) or primal (regularized) formulation\n",
    "        tol = 1e-4, # tolerance for stopping criteria\n",
    "        C = 1.0, # inverse of regularization strength, smaller = stronger regularization\n",
    "        fit_intercept = True, # add bias to decision function\n",
    "        intercept_scaling = 1.0, # for use with liblinear solver\n",
    "        class_weight = None, # dict of weights or 'balanced'\n",
    "        random_state=RANDOM_SEED,\n",
    "        solver='lbfgs', # lbfgs, liblinear, newton-cg, newton-cholesky, sag, saga\n",
    "    )\n",
    "    lr_default.fit(X_train, y_train)\n",
    "with Timer('logistic regression (untuned) test set eval time'):\n",
    "    y_pred_lr_default = lr_default.predict(X_test)\n",
    "\n",
    "print(classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred_lr_default,\n",
    "    labels=list(int_labels),\n",
    "    target_names=list(str_labels),\n",
    "    sample_weight=None,\n",
    "    digits=4,\n",
    "    output_dict=False,\n",
    "))\n",
    "\n",
    "pprint(lr_default.get_params())\n",
    "\n",
    "lr_params = {\n",
    "    'C': np.logspace(-4, 4, 20)\n",
    "}\n",
    "\n",
    "with Timer('logistic regression hyperparameter tuning'):\n",
    "    lr_grid_search = GridSearchCV(\n",
    "        estimator=lr_default,\n",
    "        param_grid=lr_params,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1, # use all cpus\n",
    "        refit=True,\n",
    "        cv=5,\n",
    "        verbose=3,\n",
    "        error_score=np.nan,\n",
    "        return_train_score=False,\n",
    "    )\n",
    "    lr_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# parameter setting that gave the best results on the hold out data\n",
    "pprint(lr_grid_search.best_params_ )\n",
    "# mean cross-validated score of the best_estimator\n",
    "print('best score: ', lr_grid_search.best_score_)\n",
    "\n",
    "lr = lr_grid_search.best_estimator_\n",
    "\n",
    "with Timer('logistic regression (tuned) test set eval time'):\n",
    "    y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "print(classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred_lr,\n",
    "    labels=list(int_labels),\n",
    "    target_names=list(str_labels),\n",
    "    sample_weight=None,\n",
    "    digits=4,\n",
    "    output_dict=False,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213487f9",
   "metadata": {},
   "source": [
    "```text\n",
    "logistic regression (untuned) training time: 3.160173791984562 seconds\n",
    "logistic regression (untuned) test set eval time: 0.0327206660003867 seconds\n",
    "                      precision    recall  f1-score   support\n",
    "\n",
    "       are_you_a_bot     0.9474    1.0000    0.9730        18\n",
    "          calculator     0.9062    0.8788    0.8923        33\n",
    "                date     0.9655    0.9655    0.9655        29\n",
    "          definition     1.0000    0.9062    0.9508        32\n",
    "          find_phone     0.9167    1.0000    0.9565        22\n",
    "           flip_coin     1.0000    1.0000    1.0000        31\n",
    "food_beverage_recipe     0.7234    0.9714    0.8293        35\n",
    "             goodbye     0.9355    0.8788    0.9062        33\n",
    "            greeting     0.8438    0.8710    0.8571        31\n",
    "               maybe     0.7692    0.8333    0.8000        24\n",
    "     meaning_of_life     1.0000    1.0000    1.0000        37\n",
    "                  no     0.8857    0.8857    0.8857        35\n",
    "            reminder     0.9231    0.9231    0.9231        26\n",
    "     reminder_update     0.9444    0.9714    0.9577        35\n",
    "       shopping_list     0.9032    0.9333    0.9180        30\n",
    "shopping_list_update     0.9630    0.8966    0.9286        29\n",
    "            spelling     1.0000    0.9655    0.9825        29\n",
    "           tell_joke     0.9630    0.9630    0.9630        27\n",
    "                text     0.9643    1.0000    0.9818        27\n",
    "                time     1.0000    0.9667    0.9831        30\n",
    "               timer     1.0000    0.9000    0.9474        30\n",
    "           todo_list     0.8800    0.8800    0.8800        25\n",
    "    todo_list_update     0.9355    0.9062    0.9206        32\n",
    "             traffic     1.0000    0.9500    0.9744        40\n",
    "           translate     0.8462    0.8800    0.8627        25\n",
    "             weather     0.9600    0.9231    0.9412        26\n",
    "   what_is_your_name     0.8125    0.9286    0.8667        28\n",
    "        who_made_you     0.9714    0.9189    0.9444        37\n",
    "     word_of_the_day     0.8919    1.0000    0.9429        33\n",
    "                 yes     1.0000    0.6667    0.8000        33\n",
    "\n",
    "            accuracy                         0.9246       902\n",
    "           macro avg     0.9284    0.9255    0.9245       902\n",
    "        weighted avg     0.9304    0.9246    0.9249       902\n",
    "\n",
    "{'C': 1.0,\n",
    " 'class_weight': None,\n",
    " 'dual': False,\n",
    " 'fit_intercept': True,\n",
    " 'intercept_scaling': 1.0,\n",
    " 'l1_ratio': None,\n",
    " 'max_iter': 100,\n",
    " 'multi_class': 'deprecated',\n",
    " 'n_jobs': None,\n",
    " 'penalty': 'l2',\n",
    " 'random_state': 42,\n",
    " 'solver': 'lbfgs',\n",
    " 'tol': 0.0001,\n",
    " 'verbose': 0,\n",
    " 'warm_start': False}\n",
    "\n",
    "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
    "[CV 1/5] END ...........C=0.0006951927961775605;, score=0.037 total time=   2.3s\n",
    "[CV 4/5] END ..........C=0.00026366508987303583;, score=0.037 total time=   2.5s\n",
    "[truncated]\n",
    "[CV 5/5] END .........................C=10000.0;, score=0.920 total time=   2.6s\n",
    "[CV 4/5] END .........................C=10000.0;, score=0.910 total time=   3.5s\n",
    "\n",
    "logistic regression hyperparameter tuning: 42.528201458015246 seconds\n",
    "{'C': 545.5594781168514}\n",
    "best score:  0.93477537437604\n",
    "\n",
    "logistic regression (tuned) test set eval time: 0.019191125000361353 seconds\n",
    "                      precision    recall  f1-score   support\n",
    "\n",
    "       are_you_a_bot     1.0000    0.9444    0.9714        18\n",
    "          calculator     0.9118    0.9394    0.9254        33\n",
    "                date     0.9655    0.9655    0.9655        29\n",
    "          definition     0.9688    0.9688    0.9688        32\n",
    "          find_phone     1.0000    1.0000    1.0000        22\n",
    "           flip_coin     1.0000    1.0000    1.0000        31\n",
    "food_beverage_recipe     0.8750    1.0000    0.9333        35\n",
    "             goodbye     0.9697    0.9697    0.9697        33\n",
    "            greeting     0.8750    0.9032    0.8889        31\n",
    "               maybe     0.8462    0.9167    0.8800        24\n",
    "     meaning_of_life     1.0000    1.0000    1.0000        37\n",
    "                  no     0.9394    0.8857    0.9118        35\n",
    "            reminder     0.9259    0.9615    0.9434        26\n",
    "     reminder_update     0.9714    0.9714    0.9714        35\n",
    "       shopping_list     0.9091    1.0000    0.9524        30\n",
    "shopping_list_update     1.0000    0.8966    0.9455        29\n",
    "            spelling     1.0000    0.9655    0.9825        29\n",
    "           tell_joke     1.0000    1.0000    1.0000        27\n",
    "                text     1.0000    1.0000    1.0000        27\n",
    "                time     1.0000    0.9667    0.9831        30\n",
    "               timer     1.0000    0.9333    0.9655        30\n",
    "           todo_list     1.0000    0.9200    0.9583        25\n",
    "    todo_list_update     0.9688    0.9688    0.9688        32\n",
    "             traffic     1.0000    0.9750    0.9873        40\n",
    "           translate     0.9200    0.9200    0.9200        25\n",
    "             weather     0.9259    0.9615    0.9434        26\n",
    "   what_is_your_name     0.8387    0.9286    0.8814        28\n",
    "        who_made_you     0.9706    0.8919    0.9296        37\n",
    "     word_of_the_day     0.9706    1.0000    0.9851        33\n",
    "                 yes     0.8710    0.8182    0.8438        33\n",
    "\n",
    "            accuracy                         0.9523       902\n",
    "           macro avg     0.9541    0.9524    0.9525       902\n",
    "        weighted avg     0.9541    0.9523    0.9525       902\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843bc33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multinomial naive bayes\n",
    "\n",
    "with Timer('multinomial naive bayes (untuned) training time'):\n",
    "    nb_default = MultinomialNB(\n",
    "        alpha=1.0, # Laplace smoothing (set < 1 for Lidstone)\n",
    "        force_alpha=True, # avoid numerical errors\n",
    "        fit_prior=True, # calculate class prior probabilities based on the frequency of each class in the training data\n",
    "    )\n",
    "    nb_default.fit(X_train, y_train)\n",
    "with Timer('multinomial naive bayes (untuned) test set eval time'):\n",
    "    y_pred_nb_default = nb_default.predict(X_test)\n",
    "\n",
    "print(classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred_nb_default,\n",
    "    labels=list(int_labels),\n",
    "    target_names=list(str_labels),\n",
    "    sample_weight=None,\n",
    "    digits=4,\n",
    "    output_dict=False,\n",
    "))\n",
    "\n",
    "pprint(nb_default.get_params())\n",
    "\n",
    "nb_params = {\n",
    "    'alpha': (1.0, 0.6, 0.3, 0.1)\n",
    "}\n",
    "\n",
    "with Timer('multinomial naive bayes hyperparameter tuning'):\n",
    "    nb_grid_search = GridSearchCV(\n",
    "        estimator=nb_default,\n",
    "        param_grid=nb_params,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1, # use all cpus\n",
    "        refit=True,\n",
    "        cv=5,\n",
    "        verbose=3,\n",
    "        error_score=np.nan,\n",
    "        return_train_score=False,\n",
    "    )\n",
    "    nb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# parameter setting that gave the best results on the hold out data\n",
    "pprint(nb_grid_search.best_params_ )\n",
    "# mean cross-validated score of the best_estimator\n",
    "print('best score: ', nb_grid_search.best_score_)\n",
    "\n",
    "nb = nb_grid_search.best_estimator_\n",
    "\n",
    "with Timer('multinomial naive bayes (tuned) test set eval time'):\n",
    "    y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "print(classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred_nb,\n",
    "    labels=list(int_labels),\n",
    "    target_names=list(str_labels),\n",
    "    sample_weight=None,\n",
    "    digits=4,\n",
    "    output_dict=False,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4403fdd9",
   "metadata": {},
   "source": [
    "```text\n",
    "multinomial naive bayes (untuned) training time: 0.06071029099985026 seconds\n",
    "multinomial naive bayes (untuned) test set eval time: 0.018574333982542157 seconds\n",
    "                      precision    recall  f1-score   support\n",
    "\n",
    "       are_you_a_bot     0.7200    1.0000    0.8372        18\n",
    "          calculator     1.0000    0.6970    0.8214        33\n",
    "                date     0.8485    0.9655    0.9032        29\n",
    "          definition     1.0000    0.5938    0.7451        32\n",
    "          find_phone     0.8462    1.0000    0.9167        22\n",
    "           flip_coin     1.0000    1.0000    1.0000        31\n",
    "food_beverage_recipe     1.0000    0.8571    0.9231        35\n",
    "             goodbye     0.9615    0.7576    0.8475        33\n",
    "            greeting     0.9259    0.8065    0.8621        31\n",
    "               maybe     0.8750    0.8750    0.8750        24\n",
    "     meaning_of_life     0.8222    1.0000    0.9024        37\n",
    "                  no     0.9091    0.8571    0.8824        35\n",
    "            reminder     0.8929    0.9615    0.9259        26\n",
    "     reminder_update     0.9444    0.9714    0.9577        35\n",
    "       shopping_list     0.8000    0.9333    0.8615        30\n",
    "shopping_list_update     0.9259    0.8621    0.8929        29\n",
    "            spelling     0.9667    1.0000    0.9831        29\n",
    "           tell_joke     0.9643    1.0000    0.9818        27\n",
    "                text     0.9643    1.0000    0.9818        27\n",
    "                time     1.0000    1.0000    1.0000        30\n",
    "               timer     0.9000    0.9000    0.9000        30\n",
    "           todo_list     0.8214    0.9200    0.8679        25\n",
    "    todo_list_update     0.9667    0.9062    0.9355        32\n",
    "             traffic     0.9756    1.0000    0.9877        40\n",
    "           translate     0.7419    0.9200    0.8214        25\n",
    "             weather     0.9583    0.8846    0.9200        26\n",
    "   what_is_your_name     0.7500    0.9643    0.8438        28\n",
    "        who_made_you     0.9714    0.9189    0.9444        37\n",
    "     word_of_the_day     0.8250    1.0000    0.9041        33\n",
    "                 yes     0.9565    0.6667    0.7857        33\n",
    "\n",
    "            accuracy                         0.9035       902\n",
    "           macro avg     0.9078    0.9073    0.9004       902\n",
    "        weighted avg     0.9144    0.9035    0.9018       902\n",
    "\n",
    "{'alpha': 1.0, 'class_prior': None, 'fit_prior': True, 'force_alpha': True}\n",
    "\n",
    "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
    "[CV 1/5] END .........................alpha=1.0;, score=0.872 total time=   0.2s\n",
    "[CV 5/5] END .........................alpha=1.0;, score=0.902 total time=   0.2s\n",
    "[truncated]\n",
    "[CV 3/5] END .........................alpha=0.1;, score=0.895 total time=   0.1s\n",
    "[CV 4/5] END .........................alpha=0.1;, score=0.887 total time=   0.1s\n",
    "\n",
    "multinomial naive bayes hyperparameter tuning: 0.6898890830052551 seconds\n",
    "{'alpha': 0.3}\n",
    "best score:  0.9084858569051579\n",
    "\n",
    "multinomial naive bayes (tuned) test set eval time: 0.018093249993398786 seconds\n",
    "                      precision    recall  f1-score   support\n",
    "\n",
    "       are_you_a_bot     0.7200    1.0000    0.8372        18\n",
    "          calculator     1.0000    0.7879    0.8814        33\n",
    "                date     0.8485    0.9655    0.9032        29\n",
    "          definition     1.0000    0.6562    0.7925        32\n",
    "          find_phone     0.9167    1.0000    0.9565        22\n",
    "           flip_coin     1.0000    1.0000    1.0000        31\n",
    "food_beverage_recipe     0.9375    0.8571    0.8955        35\n",
    "             goodbye     0.9630    0.7879    0.8667        33\n",
    "            greeting     0.9231    0.7742    0.8421        31\n",
    "               maybe     0.8750    0.8750    0.8750        24\n",
    "     meaning_of_life     0.8605    1.0000    0.9250        37\n",
    "                  no     0.9062    0.8286    0.8657        35\n",
    "            reminder     0.8929    0.9615    0.9259        26\n",
    "     reminder_update     0.9459    1.0000    0.9722        35\n",
    "       shopping_list     0.8485    0.9333    0.8889        30\n",
    "shopping_list_update     0.8667    0.8966    0.8814        29\n",
    "            spelling     0.9655    0.9655    0.9655        29\n",
    "           tell_joke     1.0000    1.0000    1.0000        27\n",
    "                text     0.9643    1.0000    0.9818        27\n",
    "                time     1.0000    1.0000    1.0000        30\n",
    "               timer     0.9000    0.9000    0.9000        30\n",
    "           todo_list     0.9200    0.9200    0.9200        25\n",
    "    todo_list_update     0.9677    0.9375    0.9524        32\n",
    "             traffic     0.9756    1.0000    0.9877        40\n",
    "           translate     0.7742    0.9600    0.8571        25\n",
    "             weather     0.8846    0.8846    0.8846        26\n",
    "   what_is_your_name     0.7500    0.9643    0.8438        28\n",
    "        who_made_you     0.9714    0.9189    0.9444        37\n",
    "     word_of_the_day     0.8684    1.0000    0.9296        33\n",
    "                 yes     0.9130    0.6364    0.7500        33\n",
    "\n",
    "            accuracy                         0.9102       902\n",
    "           macro avg     0.9120    0.9137    0.9075       902\n",
    "        weighted avg     0.9174    0.9102    0.9086       902\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce688b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# support vector machine\n",
    "\n",
    "with Timer('support vector machine (untuned) training time'):\n",
    "    svm_default = SVC(\n",
    "        kernel='linear', # 'rbf' (default), 'linear', 'poly', 'sigmoid', 'precomputed'\n",
    "        C=1, # regularization\n",
    "        gamma='scale', # 'scale', 'auto'\n",
    "        coef0=0.0, # independent term for 'poly' and 'sigmoid'\n",
    "        shrinking=True, # shrinking heuristic\n",
    "        probability=False, # probability estimates\n",
    "        tol=0.001, # tolerance for stopping criterion\n",
    "        random_state=RANDOM_SEED,\n",
    "        verbose=False,\n",
    "        cache_size=1000, # use 1GB for kernel cache\n",
    "    )\n",
    "    svm_default.fit(X_train, y_train)\n",
    "\n",
    "with Timer('support vector machine (untuned) test set eval time'):\n",
    "    y_pred_svm_default = svm_default.predict(X_test)\n",
    "\n",
    "print(classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred_svm_default,\n",
    "    labels=list(int_labels),\n",
    "    target_names=list(str_labels),\n",
    "    sample_weight=None,\n",
    "    digits=4,\n",
    "    output_dict=False,\n",
    "))\n",
    "\n",
    "pprint(svm_default.get_params())\n",
    "\n",
    "svm_params = {\n",
    "    'C': (0.1, 1, 10, 100, 1000),\n",
    "    'gamma': ('scale', 1.0, 0.1, 0.01, 0.001, 0.0001),\n",
    "    'kernel': ('rbf', 'linear')\n",
    "}\n",
    "\n",
    "\n",
    "with Timer('support vector machine hyperparameter tuning'):\n",
    "    svm_grid_search = GridSearchCV(\n",
    "        estimator=svm_default,\n",
    "        param_grid=svm_params,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1, # use all cpus\n",
    "        refit=True,\n",
    "        cv=5,\n",
    "        verbose=3,\n",
    "        error_score=np.nan,\n",
    "        return_train_score=False,\n",
    "    )\n",
    "\n",
    "    svm_grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# parameter setting that gave the best results on the hold out data\n",
    "pprint(svm_grid_search.best_params_ )\n",
    "# mean cross-validated score of the best_estimator\n",
    "print('best score: ', svm_grid_search.best_score_)\n",
    "\n",
    "svm = svm_grid_search.best_estimator_\n",
    "\n",
    "with Timer('support vector machine (tuned) test set eval time'):\n",
    "    y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "print(classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred_svm,\n",
    "    labels=list(int_labels),\n",
    "    target_names=list(str_labels),\n",
    "    sample_weight=None,\n",
    "    digits=4,\n",
    "    output_dict=False,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2998c9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "```text\n",
    "support vector machine (untuned) training time: 11.474093458993593 seconds\n",
    "support vector machine (untuned) test set eval time: 3.43490262501291 seconds\n",
    "                      precision    recall  f1-score   support\n",
    "\n",
    "       are_you_a_bot     1.0000    1.0000    1.0000        18\n",
    "          calculator     0.9394    0.9394    0.9394        33\n",
    "                date     1.0000    0.9310    0.9643        29\n",
    "          definition     1.0000    0.9688    0.9841        32\n",
    "          find_phone     1.0000    1.0000    1.0000        22\n",
    "           flip_coin     1.0000    1.0000    1.0000        31\n",
    "food_beverage_recipe     0.7727    0.9714    0.8608        35\n",
    "             goodbye     0.9412    0.9697    0.9552        33\n",
    "            greeting     0.8788    0.9355    0.9062        31\n",
    "               maybe     0.8462    0.9167    0.8800        24\n",
    "     meaning_of_life     1.0000    1.0000    1.0000        37\n",
    "                  no     0.9412    0.9143    0.9275        35\n",
    "            reminder     0.9259    0.9615    0.9434        26\n",
    "     reminder_update     0.9444    0.9714    0.9577        35\n",
    "       shopping_list     0.8824    1.0000    0.9375        30\n",
    "shopping_list_update     1.0000    0.8621    0.9259        29\n",
    "            spelling     1.0000    0.9655    0.9825        29\n",
    "           tell_joke     1.0000    0.9630    0.9811        27\n",
    "                text     1.0000    1.0000    1.0000        27\n",
    "                time     1.0000    0.9333    0.9655        30\n",
    "               timer     1.0000    0.9000    0.9474        30\n",
    "           todo_list     1.0000    0.9200    0.9583        25\n",
    "    todo_list_update     0.9688    0.9688    0.9688        32\n",
    "             traffic     1.0000    0.9500    0.9744        40\n",
    "           translate     0.9583    0.9200    0.9388        25\n",
    "             weather     0.8966    1.0000    0.9455        26\n",
    "   what_is_your_name     0.8710    0.9643    0.9153        28\n",
    "        who_made_you     0.9714    0.9189    0.9444        37\n",
    "     word_of_the_day     1.0000    0.9697    0.9846        33\n",
    "                 yes     0.9000    0.8182    0.8571        33\n",
    "\n",
    "            accuracy                         0.9501       902\n",
    "           macro avg     0.9546    0.9511    0.9515       902\n",
    "        weighted avg     0.9540    0.9501    0.9507       902\n",
    "\n",
    "{'C': 1,\n",
    " 'break_ties': False,\n",
    " 'cache_size': 1000,\n",
    " 'class_weight': None,\n",
    " 'coef0': 0.0,\n",
    " 'decision_function_shape': 'ovr',\n",
    " 'degree': 3,\n",
    " 'gamma': 'scale',\n",
    " 'kernel': 'linear',\n",
    " 'max_iter': -1,\n",
    " 'probability': False,\n",
    " 'random_state': 42,\n",
    " 'shrinking': True,\n",
    " 'tol': 0.001,\n",
    " 'verbose': False}\n",
    "\n",
    "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
    "[CV 2/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.642 total time= 1.8min\n",
    "[CV 5/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.587 total time= 1.8min\n",
    "[truncated]\n",
    "[CV 4/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.917 total time= 1.0min\n",
    "[CV 5/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.933 total time=  56.5s\n",
    "\n",
    "support vector machine hyperparameter tuning: 2479.4304718750063 seconds\n",
    "{'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
    "best score:  0.9321131447587355\n",
    "\n",
    "support vector machine (tuned) test set eval time: 8.229837332997704 seconds\n",
    "                      precision    recall  f1-score   support\n",
    "\n",
    "       are_you_a_bot     1.0000    0.9444    0.9714        18\n",
    "          calculator     0.9394    0.9394    0.9394        33\n",
    "                date     1.0000    0.9655    0.9825        29\n",
    "          definition     1.0000    0.9688    0.9841        32\n",
    "          find_phone     1.0000    1.0000    1.0000        22\n",
    "           flip_coin     1.0000    1.0000    1.0000        31\n",
    "food_beverage_recipe     0.7727    0.9714    0.8608        35\n",
    "             goodbye     0.9697    0.9697    0.9697        33\n",
    "            greeting     0.8571    0.9677    0.9091        31\n",
    "               maybe     0.8462    0.9167    0.8800        24\n",
    "     meaning_of_life     1.0000    1.0000    1.0000        37\n",
    "                  no     0.9412    0.9143    0.9275        35\n",
    "            reminder     0.9259    0.9615    0.9434        26\n",
    "     reminder_update     0.9444    0.9714    0.9577        35\n",
    "       shopping_list     0.8824    1.0000    0.9375        30\n",
    "shopping_list_update     1.0000    0.8621    0.9259        29\n",
    "            spelling     1.0000    0.9655    0.9825        29\n",
    "           tell_joke     1.0000    0.9630    0.9811        27\n",
    "                text     1.0000    1.0000    1.0000        27\n",
    "                time     1.0000    0.9333    0.9655        30\n",
    "               timer     1.0000    0.9000    0.9474        30\n",
    "           todo_list     1.0000    0.9200    0.9583        25\n",
    "    todo_list_update     0.9688    0.9688    0.9688        32\n",
    "             traffic     1.0000    0.9500    0.9744        40\n",
    "           translate     0.9583    0.9200    0.9388        25\n",
    "             weather     0.9286    1.0000    0.9630        26\n",
    "   what_is_your_name     0.8710    0.9643    0.9153        28\n",
    "        who_made_you     0.9714    0.9189    0.9444        37\n",
    "     word_of_the_day     1.0000    0.9697    0.9846        33\n",
    "                 yes     0.9000    0.8182    0.8571        33\n",
    "\n",
    "            accuracy                         0.9512       902\n",
    "           macro avg     0.9559    0.9515    0.9523       902\n",
    "        weighted avg     0.9552    0.9512    0.9518       902\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b83f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and metadata\n",
    "\n",
    "PICKLE_PROTOCOL = 5\n",
    "PICKLE_FILE_EXTENSIONS = ('.p', '.pkl')\n",
    "\n",
    "def save_model(model: BaseEstimator, model_path: Path | str) -> Path:\n",
    "    '''\n",
    "    Saves model to the given path with timestamp in filename\n",
    "    Saves metadata (python and library versions) in a text file alongside model\n",
    "    '''\n",
    "    timestamp = int(time.time())\n",
    "    model_path = Path(model_path)\n",
    "    if model_path.suffix not in PICKLE_FILE_EXTENSIONS:\n",
    "        raise Exception(f'Model file must end in one of these: {PICKLE_FILE_EXTENSIONS}')\n",
    "    if not re.search(r'\\d{10}$', model_path.stem):\n",
    "        # add timestamp to path if one isn't present already\n",
    "        model_path = model_path.parent / f'{model_path.stem}_{timestamp}{model_path.suffix}'\n",
    "    with model_path.open('wb') as f:\n",
    "        joblib.dump(model, f, protocol=PICKLE_PROTOCOL)\n",
    "    print(f'saved model to {model_path}')\n",
    "    # save metadata alongside model\n",
    "    python = [sys.executable, '-VV']\n",
    "    pip = ['uv', 'pip', 'freeze']\n",
    "    results = [subprocess.run(command, capture_output=True, text=True) for command in (python, pip)]\n",
    "    metadata_path = model_path.parent / f'{model_path.stem}.txt'\n",
    "    with metadata_path.open('w+') as f:\n",
    "        f.write('\\n'.join([re.sub(r'\\033\\[[0-9;]*m', '', r.stdout) for r in results]))\n",
    "    print(f'saved metadata to {metadata_path}')\n",
    "    return model_path\n",
    "\n",
    "# save model with highest accuracy (logistic regression) and predictions\n",
    "df_pred = pd.DataFrame({'prediction': y_pred_lr})\n",
    "df_pred.to_json(DATA_DIR / 'y_pred_lr.jsonl', orient='records', lines=True)\n",
    "\n",
    "saved_model_path = save_model(lr, MODEL_DIR / f'model_{timestamp}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68600243",
   "metadata": {},
   "source": [
    "```text\n",
    "saved model...\n",
    "saved metadata...\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
