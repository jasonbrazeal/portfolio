{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "000f9cbb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Data Augmentation\n",
    "\n",
    "One relatively fast way to generate new data for the 2 missing intents is to use an LLM.\n",
    "\n",
    "To ensure diversity in the generated utterances, we'll use a technique described [here](https://arxiv.org/abs/2209.11755) and [here](https://www.promptingguide.ai/applications/generating_textbooks).\n",
    "\n",
    "From promptingguide.ai:\n",
    "* Identify which parameters/entities might vary between different samples in your synthetic dataset\n",
    "* Generate or manually compile a collection of these entities to fill in the gaps\n",
    "* Produce the dataset by randomly selecting entities for insertion. It's best to set the generation temperature higher than the default but below the maximum\n",
    "\n",
    "We will instruct the LLM to use 3 different language styles to introduce some variation in the generated data. We create 3 examples for each style, so we have to come up with 9 examples for each of the 2 missing intents. We will have the LLM create 50 examples of each style and add these utterances to our dataset.\n",
    "\n",
    "The final 300 generated utterances are in `data_generated.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4514a8c5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "from openai import OpenAI\n",
    "from openai.types.chat.chat_completion_message_param import ChatCompletionMessageParam\n",
    "from pandas import DataFrame\n",
    "from pydantic import BaseModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import (\n",
    "    init_nb, GENERATED_DATA_PATH, ALL_DATA_PATH, FILTERED_DATA_PATH\n",
    ")\n",
    "init_nb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52887d21",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# LLM setup\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', '')\n",
    "# https://platform.openai.com/docs/models\n",
    "# gpt-4o & gpt-4o-mini: 128K context, October 2023 knowledge cutoff, 16,384 max output tokens\n",
    "# LLM_MODEL = 'gpt-4o-2024-08-06' # supports structured outputs\n",
    "LLM_MODEL = 'gpt-4o-mini-2024-07-18'\n",
    "# https://platform.openai.com/docs/api-reference/chat/create\n",
    "# temperature ranges 0-2, default 1, we set it a bit higher to induce more variation\n",
    "LLM_TEMPERATURE: float = 1.2\n",
    "SYSTEM_PROMPT: str = 'you are an accomplished fiction writer, an expert at writing in different language styles'\n",
    "\n",
    "client: OpenAI = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Note: in my testing, the gpt-4o-mini model seemed to perform better with the\n",
    "# higher-than-default temperature setting. The gpt-4o model produced output\n",
    "# that I found a bit too flowery, such as:\n",
    "# \"blessed machine of knowledge, mention today's verbiage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f86a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM helpers\n",
    "\n",
    "\n",
    "# for structured output\n",
    "class ResponseFormat(BaseModel):\n",
    "    utterances: list[str]\n",
    "\n",
    "\n",
    "def generate_text(prompt: str) -> list[str]:\n",
    "    '''\n",
    "    Generate LLM text from a prompt\n",
    "    '''\n",
    "    messages: list[ChatCompletionMessageParam] = [\n",
    "            {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "            {'role': 'user', 'content': prompt}\n",
    "    ]\n",
    "    try:\n",
    "        response = client.beta.chat.completions.parse(\n",
    "            model=LLM_MODEL,\n",
    "            messages = messages,\n",
    "            temperature=LLM_TEMPERATURE,\n",
    "            response_format=ResponseFormat,\n",
    "        )\n",
    "        output = response.choices[0].message.parsed\n",
    "        return output.utterances\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []\n",
    "\n",
    "\n",
    "def generate_utterances(intent, language_style_examples) -> list[str]:\n",
    "    '''\n",
    "    Generate utterances for an intent given a few examples in different styles\n",
    "    '''\n",
    "    utterances = []\n",
    "    for language_style, examples in tqdm(language_style_examples.items()):\n",
    "        # construct prompt\n",
    "        prompt = f'''\n",
    "        Task: Come up with 50 different ways that a user could ask an AI assistant about {intent}.\n",
    "        The output should be lowercase without any final punctuation and should use {language_style}.\n",
    "\n",
    "        Examples:\n",
    "        '''\n",
    "        prompt += '\\n'.join([f'{i}. {example}' for i, example in enumerate(examples)])\n",
    "\n",
    "        # generate text\n",
    "        utterances += generate_text(prompt)\n",
    "\n",
    "    return utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1baaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use LLM to generate new data\n",
    "\n",
    "# generate new utterances using data that I created for the missing intents\n",
    "# we are printing out a sample of the generated utterances to make sure\n",
    "# they are what we expect\n",
    "language_style_examples_word_of_the_day = {\n",
    "    'formal language': [\n",
    "        \"what is the word of the day, kind sir\",\n",
    "        \"pardon me, madam, could you please tell me the word of the day today\",\n",
    "        \"i will have today's word of the day now, please\",\n",
    "    ],\n",
    "    'informal city slang': [\n",
    "        \"word of the day, bro, what it is\",\n",
    "        \"yo what the word today\",\n",
    "        \"lemme get dat word of the day\",\n",
    "    ],\n",
    "    'standard English, not too formal or informal': [\n",
    "        \"what is the word of the day\",\n",
    "        \"what's the word of the day today\",\n",
    "        \"what's today's word of the day\",\n",
    "    ]\n",
    "}\n",
    "print('generating word_of_the_day utterances...')\n",
    "generated_utterances_word_of_the_day: list[str] = generate_utterances(\n",
    "    'the word of the day', language_style_examples_word_of_the_day\n",
    ")\n",
    "print('word_of_the_day sample:')\n",
    "pprint(random.sample(generated_utterances_word_of_the_day, 10))\n",
    "\n",
    "language_style_examples_food_beverage_recipe = {\n",
    "    'formal language': [\n",
    "        \"please sir, do you know how to cook beef wellington\",\n",
    "        \"pardon, could i please have the recipe for salisbury steak with mushroom gravy\",\n",
    "        \"i would love to know how to make a fancy mojito cocktail, please\",\n",
    "    ],\n",
    "    'informal city slang': [\n",
    "        \"hey, how can i make me some mac n cheese\",\n",
    "        \"how do i cook these noodles bro\",\n",
    "        \"recipe for some awesome tacos\",\n",
    "    ],\n",
    "    'standard English, not too formal or informal': [\n",
    "        \"what is the recipe for a southern style turkey dressing\",\n",
    "        \"could you tell me how to make a stawberry daiquiri\",\n",
    "        \"what are the instructions to cook a perfect loaded baked potato\",\n",
    "    ]\n",
    "}\n",
    "print('generating food_beverage_recipe utterances...')\n",
    "generated_utterances_food_beverage_recipe: list[str] = generate_utterances(\n",
    "    'food and beverage recipes', language_style_examples_food_beverage_recipe\n",
    ")\n",
    "print('food_beverage_recipe sample:')\n",
    "pprint(random.sample(generated_utterances_food_beverage_recipe, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685ab7a7",
   "metadata": {},
   "source": [
    "```text\n",
    "generating word_of_the_day utterances...\n",
    "100%|██████████| 3/3 [00:30<00:00, 10.07s/it]\n",
    "\n",
    "word_of_the_day sample:\n",
    "['give me the scoop on the word',\n",
    " 'is there a specific word designated for today',\n",
    " 'got that daily word for me',\n",
    " 'whats today’s word highlight',\n",
    " 'that which is today’s word of the day, if you could',\n",
    " 'may i request the word of the day',\n",
    " 'what’s cookin in the word of the day',\n",
    " \"if it isn't too much trouble, what is the word of the day\",\n",
    " 'can i peep the word of the day',\n",
    " 'whats the daily slang word']\n",
    "\n",
    "generating food_beverage_recipe utterances...\n",
    "100%|██████████| 3/3 [00:28<00:00,  9.49s/it]\n",
    "\n",
    "food_beverage_recipe sample:\n",
    "['what are the instructions for preparing ratatouille',\n",
    " 'can you provide instructions for making chili con carne',\n",
    " 'got a dope pizza recipe to share',\n",
    " 'how can i make homemade hummus',\n",
    " \"what's the best way to cook a filet mignon\",\n",
    " \"show me how to make some dope s'mores\",\n",
    " 'i am interested in learning how to prepare a classic coq au vin',\n",
    " 'could you elaborate on how to enjoy a perfect hot chocolate',\n",
    " 'what are the steps to whip up a fruit smoothie',\n",
    " 'can we chat about pancake toppings, my dude']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab6910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce complete dataset\n",
    "\n",
    "# # aggregate the generated data into a dataframe\n",
    "# all_generated_utterances: dict = {\n",
    "#     'utterance': [*generated_utterances_word_of_the_day, *generated_utterances_food_beverage_recipe],\n",
    "#     'intent_str': ['word_of_the_day'] * len(generated_utterances_word_of_the_day) + ['food_beverage_recipe'] * len(generated_utterances_food_beverage_recipe),\n",
    "# }\n",
    "# df_generated: DataFrame = DataFrame(all_generated_utterances)\n",
    "\n",
    "# # save all generated data to a csv\n",
    "# df_generated.to_json(GENERATED_DATA_PATH, orient='records', lines=True)\n",
    "\n",
    "df_generated = pd.read_json(GENERATED_DATA_PATH, orient='records', lines=True)\n",
    "# add generated data to existing (filtered) data\n",
    "\n",
    "# read in filtered data\n",
    "df = pd.read_json(FILTERED_DATA_PATH, orient='records', lines=True)\n",
    "\n",
    "# first add new column to identify llm-generated text in both dataframes\n",
    "df_generated['llm_generated'] = True\n",
    "df['llm_generated'] = False\n",
    "\n",
    "# concatenate generated utterances to existing dataframe and save to csv\n",
    "df = pd.concat((df, df_generated))\n",
    "df = df.reset_index(drop=True)\n",
    "display(df)\n",
    "\n",
    "# the llm-generated data and the CLINC-150 data contain both normal apostrophes (') and smart ones (’)\n",
    "# it's not likely to matter, but let's standardize on normal apostrophes for more consistency\n",
    "df['utterance'] = df['utterance'].apply(lambda x: x.replace(\"’\", \"'\"))\n",
    "\n",
    "df.to_json(ALL_DATA_PATH, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708f644d",
   "metadata": {},
   "source": [
    "```text\n",
    "utterance            intent_str  \\\n",
    "0                     how would you say fly in italian             translate\n",
    "1                    what's the spanish word for pasta             translate\n",
    "2                  how would they say butter in zambia             translate\n",
    "3                       how do you say fast in spanish             translate\n",
    "4                  what's the word for trees in norway             translate\n",
    "...                                                ...                   ...\n",
    "4503   how can i create an easy pasta primavera recipe  food_beverage_recipe\n",
    "4504  can you tell me how to make homemade basil pesto  food_beverage_recipe\n",
    "4505        what's the best way to cook a filet mignon  food_beverage_recipe\n",
    "4506     how can i brighten up a simple vegetable soup  food_beverage_recipe\n",
    "4507     what are the steps to make a perfect omelette  food_beverage_recipe\n",
    "\n",
    "      llm_generated\n",
    "0             False\n",
    "1             False\n",
    "2             False\n",
    "3             False\n",
    "4             False\n",
    "...             ...\n",
    "4503           True\n",
    "4504           True\n",
    "4505           True\n",
    "4506           True\n",
    "4507           True\n",
    "\n",
    "[4508 rows x 3 columns]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
