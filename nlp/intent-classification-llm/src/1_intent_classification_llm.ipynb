{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8183e02d",
   "metadata": {},
   "source": [
    "## Intent Classification with LLMs\n",
    "\n",
    "The plan is to:\n",
    "\n",
    "* explore LLM prompting strategies for intent classification\n",
    "* informally test the performance of our prompts with different flagship models\n",
    "* select a few promising prompts / models to evaluate in the next notebook\n",
    "\n",
    "The prompts are in prompts.py, see `render_template`. The strategies we'll test are:\n",
    "\n",
    "* zero-shot prompting\n",
    "* k-shot prompting (includes one-shot, few-shot, etc.)\n",
    "* chain-of-thought prompting\n",
    "\n",
    "Note: prompts are slightly different for each model. An attempt was made to follow the\n",
    "best practices for each provider according to the links below:\n",
    "[Anthropic prompting](https://github.com/anthropics/anthropic-cookbook/blob/main/skills/classification/guide.ipynb)\n",
    "[Anthropic prompting](https://docs.anthropic.com/en/prompt-library/)\n",
    "[Google prompting](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/introduction-prompt-design)\n",
    "[Google prompting](https://ai.google.dev/gemini-api/docs/prompting-strategies)\n",
    "[OpenAI prompting](https://platform.openai.com/docs/guides/text?api-mode=responses)\n",
    "[General prompting techniques](https://www.promptingguide.ai/techniques) and references therein\n",
    "\n",
    "The current models (as of May 2025) are:\n",
    "\n",
    "* OpenAI GPT-4.1 (gpt-4.1-2025-04-14)\n",
    "* Google Gemini 2.5 Flash (gemini-2.5-flash-preview-04-17)\n",
    "* Anthropic Claude 3.7 Sonnet (claude-3-7-sonnet-20250219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f420b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from tqdm import tqdm\n",
    "\n",
    "from llm import OpenAIClient, AnthropicClient, GoogleClient\n",
    "from utils import DATA_DIR, init_nb\n",
    "\n",
    "init_nb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6fdce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new examples\n",
    "test_examples: list[dict[str, str]] = [\n",
    "    {'text': 'how is the traffic heading into SF right now?', 'intent': 'traffic'},\n",
    "    {'text': 'set an alarm for 7am tomorrow', 'intent': 'timer'},\n",
    "    {'text': 'could you please help me find my phone', 'intent': 'find_phone'},\n",
    "    {'text': \"can you text mom and tell her I'm on my way\", 'intent': 'text'},\n",
    "    {'text': 'what is 18 times 4', 'intent': 'calculator'},\n",
    "    {'text': 'tell me a random joke about ducks', 'intent': 'tell_joke'},\n",
    "    {'text': 'are you a real person or nah', 'intent': 'are_you_a_bot'},\n",
    "    {'text': 'can you add mouthwash to my shopping list', 'intent': 'shopping_list_update'},\n",
    "    {'text': 'what should i call you?', 'intent': 'what_is_your_name'},\n",
    "    {'text': 'hey there mister bot', 'intent': 'greeting'},\n",
    "]\n",
    "\n",
    "# from data_all.jsonl, downloadable with download_data.sh\n",
    "# see this project: https://github.com/jasonbrazeal/portfolio/tree/master/nlp/intent-classification\n",
    "dataset_examples: list[dict[str, str]] = [\n",
    "    {'text': 'will you please tell me my to do list', 'intent': 'todo_list'},\n",
    "    {'text': 'have you heard any great jokes lately', 'intent': 'tell_joke'},\n",
    "    {'text': \"name today's word of the day\", 'intent': 'word_of_the_day'},\n",
    "    {'text': 'can you tell me how to make homemade basil pesto', 'intent': 'food_beverage_recipe'},\n",
    "    {'text': 'how would i say nice to meet you if i were russian', 'intent': 'translate'},\n",
    "    {'text': 'las vegas weather today', 'intent': 'weather'},\n",
    "    {'text': 'tell me when two minutes are up', 'intent': 'timer'},\n",
    "    {'text': 'toss a coin i will take heads', 'intent': 'flip_coin'},\n",
    "    {'text': 'clear out my entire todo list', 'intent': 'todo_list_update'},\n",
    "    {'text': 'what is 25 percent of 6999', 'intent': 'calculator'}\n",
    "]\n",
    "\n",
    "with Path(DATA_DIR / 'intent_labels.json').open() as f:\n",
    "    intent_labels = json.load(f)\n",
    "intents: list[str] = list(intent_labels['label_str'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a921bc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic\n",
    "\n",
    "timestamp_anthropic = int(time.time())\n",
    "\n",
    "anthropic = AnthropicClient(\n",
    "    examples=dataset_examples,\n",
    "    intents=intents,\n",
    ")\n",
    "responses = []\n",
    "print('\\nAnthropic text generating...')\n",
    "for e in tqdm(test_examples):\n",
    "    for prompt_name in (\n",
    "        'anthropic.zero_shot_prompt', 'anthropic.k_shot_prompt',\n",
    "        'anthropic.zero_shot_cot_prompt', 'anthropic.k_shot_cot_prompt'\n",
    "    ):\n",
    "        response = anthropic.generate_text(e['text'], prompt_name)\n",
    "        responses.append({\n",
    "            'provider': 'anthropic',\n",
    "            'text': e['text'],\n",
    "            'true_intent': e['intent'],\n",
    "            'prompt_name': prompt_name,\n",
    "            'response': response\n",
    "        })\n",
    "\n",
    "df_anthropic = DataFrame(responses)\n",
    "# df_anthropic = pd.read_json(DATA_DIR / 'df_anthropic', orient='records', lines=True)\n",
    "print(df_anthropic)\n",
    "df_anthropic.to_json(DATA_DIR / 'llm' / f'df_anthropic_{timestamp_anthropic}.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041c9e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google\n",
    "\n",
    "timestamp_google = int(time.time())\n",
    "\n",
    "google = GoogleClient(\n",
    "    examples=dataset_examples,\n",
    "    intents=intents,\n",
    ")\n",
    "responses = []\n",
    "print('\\nGoogle text generating...')\n",
    "for e in tqdm(test_examples):\n",
    "    for prompt_name in (\n",
    "        'google.zero_shot_prompt', 'google.k_shot_prompt',\n",
    "        'google.zero_shot_cot_prompt', 'google.k_shot_cot_prompt'\n",
    "    ):\n",
    "        response = google.generate_text(e['text'], prompt_name)\n",
    "        responses.append({\n",
    "            'provider': 'google',\n",
    "            'text': e['text'],\n",
    "            'true_intent': e['intent'],\n",
    "            'prompt_name': prompt_name,\n",
    "            'response': response\n",
    "        })\n",
    "\n",
    "df_google = DataFrame(responses)\n",
    "# df_google = pd.read_json(DATA_DIR / 'df_google', orient='records', lines=True)\n",
    "print(df_google)\n",
    "df_google.to_json(DATA_DIR / 'llm' / f'df_google_{timestamp_google}.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039dbe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI\n",
    "\n",
    "timestamp_openai = int(time.time())\n",
    "\n",
    "openai = OpenAIClient(\n",
    "    examples=dataset_examples,\n",
    "    intents=intents,\n",
    ")\n",
    "responses = []\n",
    "print('\\nOpenAI text generating...')\n",
    "for e in tqdm(test_examples):\n",
    "    for prompt_name in (\n",
    "        'openai.zero_shot_prompt', 'openai.k_shot_prompt',\n",
    "        'openai.zero_shot_cot_prompt', 'openai.k_shot_cot_prompt'\n",
    "    ):\n",
    "        response = openai.generate_text(e['text'], prompt_name)\n",
    "        responses.append({\n",
    "            'provider': 'openai',\n",
    "            'text': e['text'],\n",
    "            'true_intent': e['intent'],\n",
    "            'prompt_name': prompt_name,\n",
    "            'response': response\n",
    "        })\n",
    "\n",
    "df_openai = DataFrame(responses)\n",
    "# df_openai = pd.read_json(DATA_DIR / 'df_openai', orient='records', lines=True)\n",
    "print(df_openai)\n",
    "df_openai.to_json(DATA_DIR / 'llm' / f'df_openai_{timestamp_openai}.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee3704",
   "metadata": {},
   "source": [
    "\n",
    "A few observations from examining the output in the the llm directory:\n",
    "  * extremely high accuracy among these few test examples\n",
    "  * very little variation in responses between the different models and prompts\n",
    "\n",
    "We'll carry out a more thorough evaluation in the next notebook."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
